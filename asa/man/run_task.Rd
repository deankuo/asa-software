% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/run_task.R
\name{run_task}
\alias{run_task}
\title{Run a Structured Task with the Agent}
\usage{
run_task(
  prompt,
  output_format = "text",
  temporal = NULL,
  config = NULL,
  agent = NULL,
  expected_fields = NULL,
  expected_schema = NULL,
  thread_id = NULL,
  field_status = NULL,
  budget_state = NULL,
  search_budget_limit = NULL,
  unknown_after_searches = NULL,
  finalize_on_all_fields_resolved = NULL,
  verbose = FALSE,
  allow_read_webpages = NULL,
  webpage_relevance_mode = NULL,
  webpage_embedding_provider = NULL,
  webpage_embedding_model = NULL,
  recursion_limit = NULL
)
}
\arguments{
\item{prompt}{The task prompt or question for the agent to research}

\item{output_format}{Expected output format. One of:
\itemize{
  \item "text": Returns response text (default)
  \item "json": Parse response as JSON
  \item "raw": Include full trace in result for debugging
  \item Character vector: Extract specific fields from response
}}

\item{temporal}{Named list or \code{asa_temporal} object for temporal filtering:
\itemize{
  \item time_filter: DuckDuckGo time filter - "d" (day), "w" (week),
    "m" (month), "y" (year)
  \item after: ISO 8601 date (e.g., "2020-01-01") - hint for results
    after this date (added to prompt context)
  \item before: ISO 8601 date (e.g., "2024-01-01") - hint for results
    before this date (added to prompt context)
}}

\item{config}{An \code{asa_config} object for unified configuration, or NULL
to use defaults}

\item{agent}{An asa_agent object from \code{\link{initialize_agent}}, or
NULL to use the currently initialized agent}

\item{expected_fields}{Optional character vector of field names expected in
JSON output. When provided, validates that all fields are present and
non-null. The result will include a \code{parsing_status} field with
validation details.}

\item{expected_schema}{Optional JSON schema tree used for best-effort repair
when the agent output is missing required keys (especially when
\code{recursion_limit} is reached). This should be a nested list describing
the required JSON object/array shape, following the conventions used in
\code{asa/tests/testthat/test-langgraph-remainingsteps.R}. When provided,
this bypasses prompt-based schema inference.}

\item{thread_id}{Optional stable identifier for memory folding sessions.
When provided, the same thread ID is reused so folded summaries persist
across invocations. Defaults to NULL (new thread each call).}

\item{field_status}{Optional per-field extraction ledger seed passed into the
LangGraph state. Useful for resuming partially resolved schemas.}

\item{budget_state}{Optional tool budget state seed passed into the LangGraph
state (e.g., to resume prior progress).}

\item{search_budget_limit}{Optional integer tool-call budget limit for this run.}

\item{unknown_after_searches}{Optional integer threshold after which unresolved
fields may be marked as unknown.}

\item{finalize_on_all_fields_resolved}{Optional logical flag. When TRUE, the
agent finalizes once all required fields are resolved.}

\item{verbose}{Print progress messages (default: FALSE)}

\item{allow_read_webpages}{If TRUE, allows the agent to open and read full
webpages (HTML/text) via the OpenWebpage tool. Disabled by default.}

\item{webpage_relevance_mode}{Relevance selection for opened webpages.
One of: "auto" (default), "lexical", "embeddings". When "embeddings" or
"auto" with an available provider, the tool uses vector similarity to pick
the most relevant excerpts; otherwise it falls back to lexical overlap.}

\item{webpage_embedding_provider}{Embedding provider to use for relevance.
One of: "auto" (default), "openai", "sentence_transformers".}

\item{webpage_embedding_model}{Embedding model identifier. For OpenAI,
defaults to "text-embedding-3-small". For sentence-transformers, use a
local model name (e.g., "all-MiniLM-L6-v2").}

\item{recursion_limit}{Optional maximum number of agent steps. Precedence is:
per-call value (this argument), then configured default from
\code{initialize_agent()} / \code{asa_config()}, then mode-specific fallback
(memory folding: 100; standard agent: 20).}
}
\value{
An \code{asa_result} object with:
  \itemize{
    \item prompt: The original prompt
    \item message: The agent's response text
    \item parsed: Parsed output (list for JSON/field extraction, NULL for text/raw)
    \item raw_output: Full agent trace (always included, verbose for "raw" format)
    \item trace_json: Structured trace JSON (when available)
    \item elapsed_time: Execution time in minutes
    \item status: "success" or "error"
    \item search_tier: Which search tier was used ("primp", "selenium", etc.)
    \item parsing_status: Validation result (if expected_fields provided)
    \item execution: Operational metadata (thread_id, stop_reason, status_code,
      tool budget counters, fold_count)
    \item fold_stats: Memory folding diagnostics list
    \item trace: Full execution trace (for "raw" output_format)
  }
}
\description{
Executes a research task using the AI search agent with a structured prompt
and returns parsed results. This is the primary function for running
agent tasks.
}
\details{
This function provides the primary interface for running research tasks.
For simple text responses, use \code{output_format = "text"}. For structured
outputs, use \code{output_format = "json"} or specify field names to extract.
For debugging and full trace access, use \code{output_format = "raw"}.

When temporal filtering is specified, the search tool's time filter is
temporarily set for this task and restored afterward. Date hints (after/before)
are appended to the prompt to guide the agent's search behavior.
}
\examples{
\dontrun{
# Initialize agent first
agent <- initialize_agent(backend = "openai", model = "gpt-4.1-mini")

# Simple text query
result <- run_task(
  prompt = "What is the capital of France?",
  output_format = "text",
  agent = agent
)
print(result$message)

# JSON structured output
result <- run_task(
  prompt = "Find information about Albert Einstein and return JSON with
            fields: birth_year, death_year, nationality, field_of_study",
  output_format = "json",
  agent = agent
)
print(result$parsed)

# Raw output for debugging (includes full trace in asa_result)
result <- run_task(
  prompt = "Search for information",
  output_format = "raw",
  agent = agent
)
cat(result$trace)  # View full agent trace

# With temporal filtering (past year only)
result <- run_task(
  prompt = "Find recent AI research breakthroughs",
  temporal = temporal_options(time_filter = "y"),
  agent = agent
)

# With date range hint
result <- run_task(
  prompt = "Find tech companies founded recently",
  temporal = list(
    time_filter = "y",
    after = "2020-01-01",
    before = "2024-01-01"
  ),
  agent = agent
)

# Using asa_config for unified configuration
config <- asa_config(
  backend = "openai",
  model = "gpt-4.1-mini",
  temporal = temporal_options(time_filter = "y")
)
result <- run_task(prompt, config = config)
}

}
\seealso{
\code{\link{initialize_agent}}, \code{\link{run_task_batch}},
  \code{\link{asa_config}}, \code{\link{temporal_options}}
}
